{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import stats\n",
    "import sklearn as sk\n",
    "from sklearn import discriminant_analysis\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "import tqdm as tqdm\n",
    "import random\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prec_test(prec0,prec1,n0,n1,alpha):\n",
    "    tau0=np.zeros(prec0.shape)\n",
    "    tau1=np.zeros(prec0.shape)\n",
    "    beta0=np.zeros(prec0.shape)\n",
    "    beta1=np.zeros(prec0.shape)\n",
    "    f0=np.zeros(prec0.shape)\n",
    "    f1=np.zeros(prec0.shape)   \n",
    "    theta0=np.zeros(prec0.shape)\n",
    "    theta1=np.zeros(prec0.shape)\n",
    "    t=np.zeros(prec0.shape) \n",
    "    t2=np.zeros(prec0.shape) \n",
    "    for i in range(tau0.shape[0]):\n",
    "        for j in range(tau0.shape[1]):\n",
    "            if i > j:\n",
    "                continue\n",
    "            tau0[i,j]=prec0[i,j]/(prec0[i,i]*prec0[j,j])\n",
    "            tau1[i,j]=prec1[i,j]/(prec1[i,i]*prec1[j,j])\n",
    "    for i in range(tau0.shape[0]):\n",
    "        for j in range(tau0.shape[1]):\n",
    "            if i > j:\n",
    "                continue        \n",
    "            beta0[i,j]=-prec0[i,j]/prec0[j,j]\n",
    "            beta1[i,j]=-prec1[i,j]/prec1[j,j]\n",
    "#             print(tau0[j,j])\n",
    "            f0[i,j]=tau0[i,j]/(tau0[i,i]*tau0[j,j])\n",
    "            f1[i,j]=tau1[i,j]/(tau1[i,i]*tau1[j,j])\n",
    "            theta0[i,j]=(1+tau0[i,i]/tau0[j,j]*beta0[i,j]**2)/(n0*tau0[i,i]*tau0[j,j])\n",
    "            theta1[i,j]=(1+tau1[i,i]/tau1[j,j]*beta1[i,j]**2)/(n1*tau1[i,i]*tau1[j,j])\n",
    "            t[i,j]=(f0[i,j]-f1[i,j])/np.sqrt(theta0[i,j]+theta1[i,j])\n",
    "            t2[i,j]=(f0[i,j]-f1[i,j])**2/(theta0[i,j]+theta1[i,j])\n",
    "#     print(i,j)\n",
    "    m=max(t2.flatten())\n",
    "    q_alpha=-np.log(8*np.pi)-2*np.log(np.log(1/(1-alpha)))\n",
    "#     if m>=(q_alpha+4*np.log(prec0.shape[0])-np.log(np.log(prec0.shape[0]))):\n",
    "#         print(\"They are not equal\")\n",
    "#     else:\n",
    "#         print(\"They are equal\")\n",
    "    return(t,t2, q_alpha)\n",
    "            \n",
    "            \n",
    "            \n",
    "def t_hat(test,alpha):\n",
    "    p=test.shape[1]\n",
    "    bp=np.sqrt(4*np.log(p)-2*np.log(np.log(p)))\n",
    "    \n",
    "    candidate_t=[t for t in np.unique(np.abs(test)) if t>=0 and t<=bp]\n",
    "    t_hat=None\n",
    "    for candidate_t_hat in candidate_t:\n",
    "        if (1-scipy.stats.norm.cdf(candidate_t_hat))*p*(p-1)/max(1,np.sum(np.abs(test)>candidate_t_hat))<= alpha:\n",
    "            t_hat=candidate_t_hat\n",
    "            break\n",
    "    if t_hat==None:\n",
    "#         print(\"No feasibile t_hat found\")\n",
    "        t_hat=2*np.sqrt(np.log(p))\n",
    "    return t_hat\n",
    "                    \n",
    "class GLQDA_Replace(BaseEstimator, ClassifierMixin):\n",
    "\n",
    "    def __init__(self, class0_pen=0,class1_pen=0,backward=5):\n",
    "        self.class0_pen = class0_pen\n",
    "        self.class1_pen = class1_pen\n",
    "        self.backward = backward\n",
    "    def get_params(self,deep=True):\n",
    "        param={\"class0_pen\":self.class0_pen, \n",
    "                \"class1_pen\": self.class1_pen,\n",
    "              \"backward\": self.backward}\n",
    "        return param\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Check that X and y have correct shape\n",
    "        X, y = sk.utils.check_X_y(X, y)\n",
    "        # Store the classes seen during fit\n",
    "        self.classes_ = unique_labels(y)\n",
    "        self.X_ = X\n",
    "        self.X_reduced = X\n",
    "        self.y_ = y\n",
    "        ## QDA parameters\n",
    "        self.y0_mu=np.sum(self.y_==self.classes_[0])/len(self.y_)\n",
    "        self.y1_mu=np.sum(self.y_==self.classes_[1])/len(self.y_)\n",
    "        self.backward=min(self.backward,self.X_.shape[1])\n",
    "\n",
    "        # Initial step\n",
    "        ## Compute the whole data covariance\n",
    "        glasso_All = sk.covariance.GraphicalLasso(alpha=self.class0_pen,tol=2e-3,assume_centered=False).fit(self.X_)\n",
    "        self.group_cov=glasso_All.covariance_\n",
    "        self.group_pre=glasso_All.precision_\n",
    "        ## Calculate the group covariance matrix\n",
    "        self.glasso0 = sk.covariance.GraphicalLasso(alpha=self.class0_pen,tol=2e-3,assume_centered=False).fit(self.X_reduced[self.y_==self.classes_[0]])\n",
    "        self.glasso1 = sk.covariance.GraphicalLasso(alpha=self.class1_pen,tol=2e-3,assume_centered=False).fit(self.X_reduced[self.y_==self.classes_[1]])\n",
    "        self.pre0= self.glasso0.precision_\n",
    "        self.pre1=self.glasso1.precision_\n",
    "        \n",
    "        ## Starting for loop\n",
    "        ## Calculate difference of precision matrix\n",
    "        diff=np.sum(np.abs(self.pre0-self.pre1),axis=1)\n",
    "        diff=diff/np.sum(diff)\n",
    "        self.index=np.argsort(diff)\n",
    "        self.pre0[self.index[:self.backward],:]=self.group_pre[self.index[:self.backward],:]\n",
    "        self.pre0[:,self.index[:self.backward]]=self.group_pre[:,self.index[:self.backward]]\n",
    "        self.pre1[self.index[:self.backward],:]=self.group_pre[self.index[:self.backward],:]\n",
    "        self.pre1[:,self.index[:self.backward]]=self.group_pre[:,self.index[:self.backward]]\n",
    "\n",
    "\n",
    "#         ## Get the reduced X\n",
    "#         self.X_reduced=self.X_[:,self.index[self.backward:]]\n",
    "\n",
    "#         self.glasso0_r = sk.covariance.GraphicalLasso(alpha=self.class0_pen,tol=2e-3,assume_centered=False).fit(self.X_reduced[self.y_==self.classes_[0]])\n",
    "#         self.glasso1_r = sk.covariance.GraphicalLasso(alpha=self.class1_pen,tol=2e-3,assume_centered=False).fit(self.X_reduced[self.y_==self.classes_[1]])\n",
    "\n",
    "#         for i in range(len(self.index[self.backward:])):\n",
    "#             for j in range(len(self.index[self.backward:])):\n",
    "#                 self.pre0[self.reduced[self.backward+i],self.reduced[self.backward+j]]=self.glasso0_r.precision_[i,j]\n",
    "#                 self.pre1[self.reduced[self.backward+i],self.reduced[self.backward+j]]=self.glasso1_r.precision_[i,j]\n",
    "\n",
    "        (sign, logdet)=np.linalg.slogdet(np.linalg.inv(self.pre0))\n",
    "        self.det_cov0=sign* logdet\n",
    "        (sign, logdet)=np.linalg.slogdet(np.linalg.inv(self.pre1))\n",
    "        self.det_cov1=sign* logdet\n",
    "        \n",
    "        self.X0_mu=np.mean(self.X_[self.y_==self.classes_[0]],axis=0)\n",
    "        self.X1_mu=np.mean(self.X_[self.y_==self.classes_[1]],axis=0)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "\n",
    "        # Check is fit had been called\n",
    "        sk.utils.validation.check_is_fitted(self)\n",
    "    \n",
    "        # Input validation\n",
    "        X = sk.utils.check_array(X)\n",
    "#         X=X[:,self.reduced]\n",
    "        \n",
    "        py_0=-0.5*np.matmul(np.matmul((X-self.X0_mu),self.pre0),np.transpose(X-self.X0_mu))\n",
    "        py_0=py_0.diagonal()\n",
    "        py_0=py_0-0.5*self.det_cov0+np.log(self.y0_mu)\n",
    "        \n",
    "        py_1=-0.5*np.matmul(np.matmul((X-self.X1_mu),self.pre1),np.transpose(X-self.X1_mu))\n",
    "        py_1=py_1.diagonal()\n",
    "        py_1=py_1-0.5*self.det_cov1+np.log(self.y1_mu)\n",
    "                               \n",
    "        predict_class=[self.classes_[int(py_0[i]<py_1[i])] for i in range(len(X))]\n",
    "                               \n",
    "        return predict_class\n",
    "    \n",
    "    def predict_log_proba(self,X):\n",
    "                # Check is fit had been called\n",
    "        sk.utils.validation.check_is_fitted(self)\n",
    "\n",
    "        # Input validation\n",
    "        X = sk.utils.check_array(X)\n",
    "        py_0=-0.5*np.matmul(np.matmul((X-self.X0_mu),self.pre0),np.transpose(X-self.X0_mu))\n",
    "        py_0=py_0.diagonal()\n",
    "        py_0=py_0-0.5*np.log(self.det_cov0)+np.log(self.y0_mu)\n",
    "        \n",
    "        py_1=-0.5*np.matmul(np.matmul((X-self.X1_mu),self.pre1),np.transpose(X-self.X1_mu))\n",
    "        py_1=py_1.diagonal()\n",
    "        py_1=py_1-0.5*np.log(self.det_cov1)+np.log(self.y1_mu)\n",
    "                               \n",
    "        predict_log_proba=np.transpose([py_0,py_1])\n",
    "                               \n",
    "        return predict_log_proba\n",
    "\n",
    "    def predict_proba(self,X):\n",
    "                # Check is fit had been called\n",
    "        sk.utils.validation.check_is_fitted(self)\n",
    "\n",
    "        # Input validation\n",
    "        X = sk.utils.check_array(X)\n",
    "        py_0=-0.5*np.matmul(np.matmul((X-self.X0_mu),self.pre0),np.transpose(X-self.X0_mu))\n",
    "        py_0=py_0.diagonal()\n",
    "        py_0=py_0-0.5*np.log(self.det_cov0)+np.log(self.y0_mu)\n",
    "        \n",
    "        py_1=-0.5*np.matmul(np.matmul((X-self.X1_mu),self.pre1),np.transpose(X-self.X1_mu))\n",
    "        py_1=py_1.diagonal()\n",
    "        py_1=py_1-0.5*np.log(self.det_cov1)+np.log(self.y1_mu)\n",
    "                               \n",
    "        predict_proba=np.transpose([np.exp(py_0),np.exp(py_1)])\n",
    "                               \n",
    "        return predict_proba\n",
    "\n",
    "class GLQDA_Replace_cai(BaseEstimator, ClassifierMixin):\n",
    "\n",
    "    def __init__(self, class0_pen=0,class1_pen=0,p_val=0.01,backward=0):\n",
    "        self.class0_pen = class0_pen\n",
    "        self.class1_pen = class1_pen\n",
    "        self.backward = backward\n",
    "        self.p_val = p_val\n",
    "    def get_params(self,deep=True):\n",
    "        param={\"class0_pen\":self.class0_pen, \n",
    "                \"class1_pen\": self.class1_pen,\n",
    "              \"backward\": self.backward,\n",
    "              'p_val':self.p_val}\n",
    "        return param\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Check that X and y have correct shape\n",
    "        X, y = sk.utils.check_X_y(X, y)\n",
    "        # Store the classes seen during fit\n",
    "        self.classes_ = unique_labels(y)\n",
    "        self.X_ = X\n",
    "        self.X_reduced = X\n",
    "        self.y_ = y\n",
    "        ## QDA parameters\n",
    "        self.y0_mu=np.sum(self.y_==self.classes_[0])/len(self.y_)\n",
    "        self.y1_mu=1-self.y0_mu\n",
    "        self.backward=min(self.backward,self.X_.shape[1]-3)\n",
    "\n",
    "        # Initial step\n",
    "        ## Compute the whole data covariance\n",
    "        glasso_All = sk.covariance.GraphicalLasso(alpha=self.class0_pen,tol=2e-3,assume_centered=False).fit(self.X_)\n",
    "        self.group_cov=glasso_All.covariance_\n",
    "        self.group_pre=glasso_All.precision_\n",
    "        ## Calculate the group covariance matrix\n",
    "        self.glasso0 = sk.covariance.GraphicalLasso(alpha=self.class0_pen,tol=2e-3,assume_centered=False).fit(self.X_reduced[self.y_==self.classes_[0]])\n",
    "        self.glasso1 = sk.covariance.GraphicalLasso(alpha=self.class1_pen,tol=2e-3,assume_centered=False).fit(self.X_reduced[self.y_==self.classes_[1]])\n",
    "        self.pre0= self.glasso0.precision_\n",
    "        self.pre1=self.glasso1.precision_\n",
    "        ## Starting for loop\n",
    "        ## Calculate difference of precision matrix\n",
    "        t,t2, q=prec_test(self.pre0,self.pre1,sum(self.y_==self.classes_[0]),sum(self.y_==self.classes_[1]),self.p_val)\n",
    "        t_thresh=t_hat(t,self.p_val)\n",
    "        hypothesis=np.logical_or(np.transpose(np.abs(t)>t_thresh),np.abs(t)>t_thresh)\n",
    "        test_reject=np.sum(hypothesis,axis=0)\n",
    "        self.index=np.argsort(test_reject)\n",
    "        for i in range(len(self.index)):\n",
    "            if test_reject[self.index[i]]<1:\n",
    "                continue\n",
    "            else:\n",
    "                break\n",
    "        self.best_share=i\n",
    "        self.pre0= self.glasso0.precision_\n",
    "        self.pre1=self.glasso1.precision_\n",
    "        self.pre0[self.index[:self.best_share],:]=self.group_pre[self.index[:self.best_share],:]\n",
    "        self.pre0[:,self.index[:self.best_share]]=self.group_pre[:,self.index[:self.best_share]]\n",
    "        self.pre1[self.index[:self.best_share],:]=self.group_pre[self.index[:self.best_share],:]\n",
    "        self.pre1[:,self.index[:self.best_share]]=self.group_pre[:,self.index[:self.best_share]]\n",
    "\n",
    "        (sign, logdet)=np.linalg.slogdet(np.linalg.inv(self.pre0))\n",
    "        self.det_cov0=sign* logdet\n",
    "        (sign, logdet)=np.linalg.slogdet(np.linalg.inv(self.pre1))\n",
    "        self.det_cov1=sign* logdet\n",
    "        \n",
    "        self.X0_mu=np.mean(self.X_[self.y_==self.classes_[0]],axis=0)\n",
    "        self.X1_mu=np.mean(self.X_[self.y_==self.classes_[1]],axis=0)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "\n",
    "        # Check is fit had been called\n",
    "        sk.utils.validation.check_is_fitted(self)\n",
    "    \n",
    "        # Input validation\n",
    "        X = sk.utils.check_array(X)\n",
    "#         X=X[:,self.reduced]\n",
    "        \n",
    "        py_0=-0.5*np.matmul(np.matmul((X-self.X0_mu),self.pre0),np.transpose(X-self.X0_mu))\n",
    "        py_0=py_0.diagonal()\n",
    "        py_0=py_0-0.5*self.det_cov0+np.log(self.y0_mu)\n",
    "        \n",
    "        py_1=-0.5*np.matmul(np.matmul((X-self.X1_mu),self.pre1),np.transpose(X-self.X1_mu))\n",
    "        py_1=py_1.diagonal()\n",
    "        py_1=py_1-0.5*self.det_cov1+np.log(self.y1_mu)\n",
    "                               \n",
    "        predict_class=[self.classes_[int(py_0[i]<py_1[i])] for i in range(len(X))]\n",
    "                               \n",
    "        return predict_class\n",
    "    \n",
    "    def predict_log_proba(self,X):\n",
    "                # Check is fit had been called\n",
    "        sk.utils.validation.check_is_fitted(self)\n",
    "\n",
    "        # Input validation\n",
    "        X = sk.utils.check_array(X)\n",
    "        py_0=-0.5*np.matmul(np.matmul((X-self.X0_mu),self.pre0),np.transpose(X-self.X0_mu))\n",
    "        py_0=py_0.diagonal()\n",
    "        py_0=py_0-0.5*np.log(self.det_cov0)+np.log(self.y0_mu)\n",
    "        \n",
    "        py_1=-0.5*np.matmul(np.matmul((X-self.X1_mu),self.pre1),np.transpose(X-self.X1_mu))\n",
    "        py_1=py_1.diagonal()\n",
    "        py_1=py_1-0.5*np.log(self.det_cov1)+np.log(self.y1_mu)\n",
    "                               \n",
    "        predict_log_proba=np.transpose([py_0,py_1])\n",
    "                               \n",
    "        return predict_log_proba\n",
    "\n",
    "    def predict_proba(self,X):\n",
    "                # Check is fit had been called\n",
    "        sk.utils.validation.check_is_fitted(self)\n",
    "\n",
    "        # Input validation\n",
    "        X = sk.utils.check_array(X)\n",
    "        py_0=-0.5*np.matmul(np.matmul((X-self.X0_mu),self.pre0),np.transpose(X-self.X0_mu))\n",
    "        py_0=py_0.diagonal()\n",
    "        py_0=py_0-0.5*np.log(self.det_cov0)+np.log(self.y0_mu)\n",
    "        \n",
    "        py_1=-0.5*np.matmul(np.matmul((X-self.X1_mu),self.pre1),np.transpose(X-self.X1_mu))\n",
    "        py_1=py_1.diagonal()\n",
    "        py_1=py_1-0.5*np.log(self.det_cov1)+np.log(self.y1_mu)\n",
    "                               \n",
    "        predict_proba=np.transpose([np.exp(py_0),np.exp(py_1)])\n",
    "                               \n",
    "        return predict_proba\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLQDA Cai\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [00:02<01:54,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified columns [0, 1, 2, 4]\n",
      "True columns [0, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/50 [00:04<01:51,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified columns [1, 2, 3, 5]\n",
      "True columns [1, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3/50 [00:06<01:47,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified columns [0, 2, 3, 5]\n",
      "True columns [0, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4/50 [00:09<01:46,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified columns [0, 1, 2, 4]\n",
      "True columns [0, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [00:11<01:43,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified columns [0, 1, 3, 5]\n",
      "True columns [0, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 6/50 [00:13<01:41,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified columns [0, 1, 4, 5]\n",
      "True columns [0, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7/50 [00:16<01:38,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified columns [1, 2, 4, 5]\n",
      "True columns [1, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 8/50 [00:18<01:35,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified columns [0, 1, 2, 5]\n",
      "True columns [0, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 9/50 [00:20<01:33,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified columns [1, 2, 3, 5]\n",
      "True columns [1, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [00:22<01:31,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified columns [0, 3, 4, 5]\n",
      "True columns [0, 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [00:25<01:29,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified columns [0, 3, 4, 5]\n",
      "True columns [0, 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 12/50 [00:27<01:26,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified columns [0, 2, 3, 5]\n",
      "True columns [0, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 13/50 [00:29<01:24,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified columns [0, 2, 4, 5]\n",
      "True columns [0, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 14/50 [00:32<01:21,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified columns [1, 2, 3, 4]\n",
      "True columns [1, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [00:34<01:20,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified columns [0, 1, 2, 5]\n",
      "True columns [0, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 16/50 [00:36<01:17,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified columns [0, 2, 4, 5]\n",
      "True columns [0, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 17/50 [00:38<01:15,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified columns [1, 2, 3, 5]\n",
      "True columns [1, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 18/50 [00:41<01:12,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified columns [0, 1, 2, 5]\n",
      "True columns [0, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 19/50 [00:43<01:10,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified columns [0, 1, 2, 3]\n",
      "True columns [0, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20/50 [00:45<01:08,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified columns [0, 1, 3, 5]\n",
      "True columns [0, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21/50 [00:47<01:05,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified columns [1, 3, 4, 5]\n",
      "True columns [1, 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 22/50 [00:50<01:03,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified columns [0, 1, 2, 4]\n",
      "True columns [0, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 23/50 [00:52<01:01,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified columns [1, 2, 3, 5]\n",
      "True columns [1, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 24/50 [00:54<00:59,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified columns [0, 2, 3, 5]\n",
      "True columns [0, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [00:57<00:56,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified columns [1, 2, 4, 5]\n",
      "True columns [1, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 26/50 [00:59<00:54,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified columns [0, 2, 3, 5]\n",
      "True columns [0, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 27/50 [01:01<00:52,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified columns [2, 3, 4, 5]\n",
      "True columns [2, 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 28/50 [01:03<00:49,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified columns [0, 1, 3, 5]\n",
      "True columns [0, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 29/50 [01:06<00:47,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified columns [1, 2, 3, 5]\n",
      "True columns [1, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30/50 [01:08<00:45,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified columns [0, 3, 4, 5]\n",
      "True columns [0, 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31/50 [01:10<00:43,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified columns [0, 1, 3, 4]\n",
      "True columns [0, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 32/50 [01:12<00:40,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified columns [0, 2, 3, 5]\n",
      "True columns [0, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 33/50 [01:15<00:38,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified columns [1, 2, 4, 5]\n",
      "True columns [1, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 34/50 [01:17<00:36,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified columns [0, 2, 3, 4]\n",
      "True columns [0, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35/50 [01:19<00:34,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified columns [1, 2, 3, 5]\n",
      "True columns [1, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 36/50 [01:22<00:32,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified columns [1, 2, 4, 5]\n",
      "True columns [1, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 37/50 [01:24<00:30,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified columns [0, 1, 2, 3]\n",
      "True columns [0, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 38/50 [01:26<00:27,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified columns [0, 2, 3, 4]\n",
      "True columns [0, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 39/50 [01:29<00:25,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified columns [1, 2, 3, 5]\n",
      "True columns [1, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40/50 [01:31<00:23,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified columns [0, 1, 3, 5]\n",
      "True columns [0, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 41/50 [01:33<00:20,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified columns [0, 1, 2, 5]\n",
      "True columns [0, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 42/50 [01:36<00:18,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified columns [1, 3, 4, 5]\n",
      "True columns [1, 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 43/50 [01:38<00:16,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified columns [1, 2, 3, 5]\n",
      "True columns [1, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 44/50 [01:40<00:13,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified columns [0, 2, 3, 4]\n",
      "True columns [0, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45/50 [01:42<00:11,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified columns [0, 1, 3, 4]\n",
      "True columns [0, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 46/50 [01:45<00:09,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified columns [1, 2, 4, 5]\n",
      "True columns [1, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 47/50 [01:47<00:06,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified columns [1, 3, 4, 5]\n",
      "True columns [1, 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 48/50 [01:49<00:04,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified columns [0, 2, 4, 5]\n",
      "True columns [0, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 49/50 [01:52<00:02,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified columns [2, 3, 4, 5]\n",
      "True columns [2, 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:54<00:00,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified columns [0, 3, 4, 5]\n",
      "True columns [0, 3]\n",
      "GLQDA Mean F1 0.81(0.03)\n",
      "QDA Mean F1 0.80(0.03)\n",
      "LDA Mean F1 0.50(0.04)\n",
      "Correctly identified differnet terms:  1.00(0.00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"GLQDA Cai\")\n",
    "selected=[]\n",
    "f1_cai=[]\n",
    "f1_qda=[]\n",
    "f1_lda=[]\n",
    "cv_set=[]\n",
    "com_vars=[]\n",
    "params={'GLQDA__class0_pen': 0.05*np.arange(1,5),\n",
    " 'GLQDA__class1_pen': 0.05*np.arange(1,5),\n",
    "        'GLQDA__p_val':[0.01,0.05]\n",
    " }\n",
    "pipe = Pipeline([('scaler', sk.preprocessing.StandardScaler()), ('GLQDA', GLQDA_Replace_cai())])\n",
    "for i in tqdm.tqdm(range(50)):\n",
    "    ## Train test split\n",
    "    n_samp_p_class=500\n",
    "    vars=random.sample(range(6),4)\n",
    "    g_cov_1=np.identity(6)\n",
    "    g_cov_2=np.identity(6)\n",
    "    # g_cov_2[vars[0],vars[0]]=g_cov_2[vars[1],vars[1]]=5\n",
    "    # g_cov_2[vars[0],vars[1]]=g_cov_2[vars[1],vars[0]]=3\n",
    "    # g_cov_2[vars[2],vars[2]]=g_cov_2[vars[3],vars[3]]=5\n",
    "    # g_cov_2[vars[2],vars[3]]=g_cov_2[vars[3],vars[2]]=3\n",
    "    g_cov_2[vars[0],vars[0]]=g_cov_2[vars[1],vars[1]]=g_cov_2[vars[2],vars[2]]=g_cov_2[vars[3],vars[3]]=5\n",
    "    g_cov_2[vars[0],vars[1]]=g_cov_2[vars[1],vars[0]]=g_cov_2[vars[0],vars[2]]=g_cov_2[vars[2],vars[0]]=g_cov_2[vars[0],vars[3]]=g_cov_2[vars[3],vars[0]]= g_cov_2[vars[1],vars[2]]=g_cov_2[vars[2],vars[1]]=g_cov_2[vars[1],vars[3]]=g_cov_2[vars[3],vars[1]]=g_cov_2[vars[2],vars[3]]=g_cov_2[vars[3],vars[2]]=3\n",
    "    X_sim=np.vstack([stats.multivariate_normal([0,0,0,0,0,0],g_cov_1).rvs(n_samp_p_class),\n",
    "                stats.multivariate_normal([0,0,0,0,0,0],g_cov_2).rvs(n_samp_p_class)])\n",
    "\n",
    "    Y_sim=np.append(['Normal']*n_samp_p_class,['Schizophrenia']*n_samp_p_class)\n",
    "    X_train, X_test, y_train, y_test = sk.model_selection.train_test_split(\n",
    "       X_sim, Y_sim, test_size=0.2, random_state=i)\n",
    "    \n",
    "    ## GLQDA\n",
    "    grid_normal=sk.model_selection.GridSearchCV(pipe,param_grid=params, scoring=sk.metrics.make_scorer(sk.metrics.accuracy_score),\n",
    "                            return_train_score=True)\n",
    "    grid_normal.fit(X_train, y_train)\n",
    "    # print(sk.metrics.classification_report(y_test,grid_normal.predict(X_test)))\n",
    "    f1_cai.append(sk.metrics.accuracy_score(y_test,grid_normal.predict(X_test)))\n",
    "    # selected.append(X_train.columns.values.astype(\"str\")[grid_normal.best_estimator_[\"GLQDA\"].index[:grid_normal.best_estimator_[\"GLQDA\"].best_share]])\n",
    "    cv_set.append([i,\"GLLDA\",f1_cai[-1]])\n",
    "    \n",
    "    ##QDA\n",
    "    clf = sk.discriminant_analysis.QuadraticDiscriminantAnalysis(store_covariance=True)\n",
    "    clf.fit(X_train, y_train)\n",
    "    # print(sk.metrics.classification_report(y_test,clf.predict(X_test)))\n",
    "    f1_qda.append(sk.metrics.accuracy_score(y_test,clf.predict(X_test)))\n",
    "    cv_set.append([i,\"QDA\",f1_qda[-1]])\n",
    "\n",
    "    ## LDA\n",
    "    clf = sk.discriminant_analysis.LinearDiscriminantAnalysis(store_covariance=True)\n",
    "    clf.fit(X_train, y_train)\n",
    "    # print(sk.metrics.classification_report(y_test,clf.predict(X_test)))\n",
    "    f1_lda.append(sk.metrics.accuracy_score(y_test,clf.predict(X_test)))\n",
    "    cv_set.append([i,\"LDA\",f1_lda[-1]])\n",
    "    idf=grid_normal.best_estimator_[\"GLQDA\"].index[grid_normal.best_estimator_[\"GLQDA\"].best_share:].tolist()\n",
    "    idf.sort()\n",
    "    vars.sort()\n",
    "    print(\"Identified columns\",idf)\n",
    "\n",
    "    print(\"True columns [%s, %s]\"%(vars[0],vars[1]))\n",
    "    v1=np.zeros(6)\n",
    "    v1[idf]=1\n",
    "    v2=np.zeros(6)\n",
    "    v2[vars]=1\n",
    "\n",
    "    com_vars.append(sk.metrics.cohen_kappa_score(v1,v2))\n",
    "    # print(grid_normal.best_params_)\n",
    "print(\"GLQDA Mean F1 %.2f(%.2f)\"%(np.mean(f1_cai),np.std(f1_cai)))\n",
    "print(\"QDA Mean F1 %.2f(%.2f)\"%(np.mean(f1_qda),np.std(f1_qda)))\n",
    "print(\"LDA Mean F1 %.2f(%.2f)\"%(np.mean(f1_lda),np.std(f1_lda)))\n",
    "print(\"Correctly identified differnet terms:  %.2f(%.2f)\"%(np.mean(com_vars),np.std(com_vars)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c1111a106d7ffaaa9f2643bb82b0d2e2dbd6e95a4929d570c8200f098d6bda7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
